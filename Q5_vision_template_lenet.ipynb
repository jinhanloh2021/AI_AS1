{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOVes3x0KPRS"
      },
      "source": [
        "## Import tensorflow, keras modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izF3NkgbKPRX"
      },
      "outputs": [],
      "source": [
        "#from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds  # For loading datasets\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt     # For plotting images\n",
        "import cv2                          # For resizing images\n",
        "from keras import Model\n",
        "\n",
        "print(tf.version.VERSION)\n",
        "print(tf.keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxzWqF8mOTbb"
      },
      "outputs": [],
      "source": [
        "#testing the GPU\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc3v3STEKPRY"
      },
      "source": [
        "## Import  MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b-VAynpKPRY"
      },
      "outputs": [],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "# More dataset choices here: https://www.tensorflow.org/api_docs/python/tf/keras/datasets\n",
        "# input image dimensions\n",
        "img_x, img_y, img_z = 28, 28, 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgX6q1jaKPRZ"
      },
      "outputs": [],
      "source": [
        "# Load training data, labels; and testing data and their true labels\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# reshape the data into a 4D tensor - (sample_number, x_img_size, y_img_size, num_channels)\n",
        "# because the MNIST is greyscale, we only have a single channel - RGB colour images would have 3\n",
        "train_images = train_images.reshape(train_images.shape[0], img_x, img_y, 1)\n",
        "test_images  = test_images.reshape(test_images.shape[0], img_x, img_y, 1)\n",
        "input_shape = (img_x, img_y, img_z)\n",
        "\n",
        "# Normalize input between 0 and 1\n",
        "# Very important\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woHFTvT6KPRZ"
      },
      "outputs": [],
      "source": [
        "# Check shapes of train_images, train_labels etc\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMfp8aTiKPRZ"
      },
      "source": [
        "### Visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tBGQjzSEKPRa"
      },
      "outputs": [],
      "source": [
        "# For printing, we name each of the 10 classes below\n",
        "class_names = ['0', '1', '2', '3', '4','5', '6', '7', '8', '9']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ygsx_6QIKPRa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i].reshape(img_x, img_y), cmap=plt.cm.binary)\n",
        "    #print(train_labels[i][0])\n",
        "    plt.xlabel(class_names[train_labels[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_5SAV3mKPRb"
      },
      "source": [
        "## (a) Create and train Lenet-5 Using Keras API on MNIST dataset **[3 points]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcZhpREqKPRb"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Create a NN with 1 input layer\n",
        "1 conv2D layer, 6 filters, 5x5 filter size, stride = (1, 1), activation tanh, use padding='same' argument (check it on https://keras.io/api/layers/convolution_layers/convolution2d/ )\n",
        "1 AveragePooling2D layer (use default arguments in https://www.tensorflow.org/api_docs/python/tf/keras/layers/AveragePooling2D )\n",
        "1 conv2D layer, 16 Filters, 5x5 filter size, stride = (1, 1), activation tanh, padding='valid'\n",
        "1 AveragePooling2D layer (Default arguements)\n",
        "1 conv2D layer, 120 filters, 5x5 filter size, stride = (1, 1), activation tanh, padding='valid'\n",
        "Flatten layer\n",
        "1 Dense layer, 84 units, tanh activation\n",
        "1 output layer\n",
        "'''\n",
        "input_shape = train_images[0].shape\n",
        "model = '<<Write your code here>>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SR07kYvaKPRc"
      },
      "outputs": [],
      "source": [
        "# Compile the model with appropriate Loss function\n",
        "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), \n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA0ZMNoRKPRc"
      },
      "outputs": [],
      "source": [
        "# Train the model on MNIST dataset\n",
        "epochs = '<<your value>>\n",
        "batch_size = '<<your value>>\n",
        "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRUc37tjKPRc"
      },
      "source": [
        "##(b) Check Accuracy on Test Data **[0.5 point]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYRjR1hwKPRc"
      },
      "outputs": [],
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bN93Tv1KPRd"
      },
      "outputs": [],
      "source": [
        "# Try to get 90% or more accuracy\n",
        "print('Test accuracy:', test_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOo2uV2BKPRd"
      },
      "source": [
        "### Visualize predictions on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-JGn4yUKPRd"
      },
      "outputs": [],
      "source": [
        "# Get all predictions for test data\n",
        "predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaOgmKTtKPRe"
      },
      "outputs": [],
      "source": [
        "# Code to visualize predictions\n",
        "# Incorrect predictions are highlighted in red\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(test_images[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    predicted_label = np.argmax(predictions[i])\n",
        "    true_label = test_labels[i]\n",
        "    if predicted_label == true_label:\n",
        "      color = 'green'\n",
        "    else:\n",
        "      color = 'red'\n",
        "    plt.xlabel(\"{} ({})\".format(class_names[predicted_label], \n",
        "                                  class_names[true_label]),\n",
        "                                  color=color)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkTfnHudRixb"
      },
      "source": [
        "##(c) Download binary_alpha_digits dataset using tfds, split dataset **[1 point]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2Sq5qMRKPRe"
      },
      "outputs": [],
      "source": [
        "## write your code here\n",
        "dataset_name = \"binary_alpha_digits\"\n",
        "\n",
        "ds_images, ds_labels = '<<Code for downloading binary_alpha_digits>>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1EMLf-I3EY7"
      },
      "outputs": [],
      "source": [
        "## Split dataset into 20% testing and 80% training\n",
        "\n",
        "test_size = 0.2   # fraction of test data\n",
        "\n",
        "'<<Write additional code as required>>\n",
        "\n",
        "train_images = '<<your code>>\n",
        "train_labels = '<<your code>>\n",
        "test_images = '<<your code>>\n",
        "test_labels = '<<your code>>\n",
        "\n",
        "# Check training, testing data size\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrWcthf3UNZd"
      },
      "source": [
        "### Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TORfGo084u6N"
      },
      "outputs": [],
      "source": [
        "# Code to visualize predictions\n",
        "# Incorrect predictions are highlighted in red\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "class_names = ['0', '1', '2', '3', '4','5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i].reshape(20, 16), cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud5K8MkmUXKW"
      },
      "source": [
        "## (d) Upscale training, testing data to MNIST image size (28, 28, 1) **[2 points]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQLJomQx62y1"
      },
      "outputs": [],
      "source": [
        "'Upscale Data'\n",
        "newSize = 28\n",
        "\n",
        "# create a numpy array for storing upscaled training images\n",
        "train_upscale = np.zeros((train_images.shape[0], newSize, newSize, 1))\n",
        "'<<Write code for upscaling training data>> Look at function cv2.resize in opencv https://pythonexamples.org/python-opencv-cv2-resize-image/ \n",
        "print(train_upscale.shape)\n",
        "\n",
        "# create a numpy array for storing upscaled testing images\n",
        "test_upscale = np.zeros((test_images.shape[0], newSize, newSize, 1))\n",
        "'<<Write code for upscaling testing data>>\n",
        "print(test_upscale.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OojCkxz6nao"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "# Visualize upscaled images\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_upscale[i].reshape(28, 28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[train_labels[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tinnqZ-VUxf"
      },
      "source": [
        "##(e) Transfer learning-- Remove Last layer from your trained LeNet **[0.5 points]**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpSLUEfQ4tX8"
      },
      "outputs": [],
      "source": [
        "## You can decide whether to train the whole network again or fix layer weights from the MNIST-trained network\n",
        "## Check link: https://keras.io/getting_started/faq/#how-can-i-freeze-keras-layers \n",
        "'<<Write code for either freezing or training all layers from scratch>>\n",
        "\n",
        "## Code for removing last layer\n",
        "'<<Write code>>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDM8SanPbxaS"
      },
      "source": [
        "##(f) Transfer learning-- Add new layers to LeNet **[1.5 points]**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbvcHOin3Thp"
      },
      "outputs": [],
      "source": [
        "## Add one or more hidden layer\n",
        "## Add output layer\n",
        "'<<Write code here>>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN6KYDus-xnd"
      },
      "outputs": [],
      "source": [
        "# Compile the model with appropriate Loss function\n",
        "model.compile(optimizer=tf.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcqiWiQVWeL6"
      },
      "source": [
        "##(g) Train the model and show accuracy on the testing dataset (test_upscale) **[1.5 point]**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdTRYc29_MKM"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "39b902d85304f92b6af859c7d58facccbdc227f11318856df96fca4be92a75ba"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
